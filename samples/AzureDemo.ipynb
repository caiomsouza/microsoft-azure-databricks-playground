{"cells":[{"cell_type":"code","source":["from pyspark.mllib.tree import RandomForest, RandomForestModel\nfrom pyspark.mllib.util import MLUtils\n\n# Load and parse the data file into an RDD of LabeledPoint.\ndata = MLUtils.loadLibSVMFile(sc, '/FileStore/tables/sample_libsvm_data.txt')\n# Split the data into training and test sets (30% held out for testing)\n(trainingData, testData) = data.randomSplit([0.7, 0.3])\n\n# Train a RandomForest model.\n#  Empty categoricalFeaturesInfo indicates all features are continuous.\n#  Note: Use larger numTrees in practice.\n#  Setting featureSubsetStrategy=\"auto\" lets the algorithm choose.\nmodel = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n                                     numTrees=3, featureSubsetStrategy=\"auto\",\n                                     impurity='gini', maxDepth=4, maxBins=32)\n\n# Evaluate model on test instances and compute test error\npredictions = model.predict(testData.map(lambda x: x.features))\nlabelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\ntestErr = labelsAndPredictions.filter(\n    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\nprint('Test Error = ' + str(testErr))\nprint('Learned classification forest model:')\nprint(model.toDebugString())\n\n# Save and load model\nmodel.save(sc, \"target/tmp/myRandomForestClassificationModel2\")\nsameModel = RandomForestModel.load(sc, \"target/tmp/myRandomForestClassificationModel\")\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test Error = 0.0\nLearned classification forest model:\nTreeEnsembleModel classifier with 3 trees\n\n  Tree 0:\n    If (feature 406 &lt;= 9.5)\n     Predict: 0.0\n    Else (feature 406 &gt; 9.5)\n     If (feature 327 &lt;= 19.5)\n      Predict: 1.0\n     Else (feature 327 &gt; 19.5)\n      Predict: 0.0\n  Tree 1:\n    If (feature 371 &lt;= 9.0)\n     If (feature 606 &lt;= 41.5)\n      If (feature 356 &lt;= 19.0)\n       Predict: 1.0\n      Else (feature 356 &gt; 19.0)\n       Predict: 0.0\n     Else (feature 606 &gt; 41.5)\n      Predict: 0.0\n    Else (feature 371 &gt; 9.0)\n     If (feature 343 &lt;= 252.5)\n      Predict: 0.0\n     Else (feature 343 &gt; 252.5)\n      Predict: 1.0\n  Tree 2:\n    If (feature 461 &lt;= 46.5)\n     If (feature 379 &lt;= 47.5)\n      Predict: 0.0\n     Else (feature 379 &gt; 47.5)\n      If (feature 575 &lt;= 141.5)\n       Predict: 1.0\n      Else (feature 575 &gt; 141.5)\n       Predict: 0.0\n    Else (feature 461 &gt; 46.5)\n     Predict: 1.0\n\n</div>"]}}],"execution_count":1}],"metadata":{"name":"AzureDemo","notebookId":4228440141791594},"nbformat":4,"nbformat_minor":0}
